



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="../images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="../images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="绯色鱼的博客" href="https://colsons.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="绯色鱼的博客" href="https://colsons.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="绯色鱼的博客" href="https://colsons.github.io/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="../css/app.css?v=0.2.5">

  
  <meta name="keywords" content="python,lstm,mindspore,keras,torch,tensorflow" />


<link rel="canonical" href="https://colsons.github.io/archives/bc57630c.html">



  <title>
LSTM 昇腾平台全框架指南 - 深度学习 - 昇腾 |
Lab Chen = 绯色鱼的博客</title>
<meta name="generator" content="Hexo 5.4.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">LSTM 昇腾平台全框架指南
  </h1>
  
<div class="meta">
  <span class="item" title="Created: 2023-07-14 10:48:08">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">Posted on</span>
    <time itemprop="dateCreated datePublished" datetime="2023-07-14T10:48:08+08:00">2023-07-14</time>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="Toggle navigation bar">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">Lab Chen</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipeyhsblkj20zk0m81kx.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipevo9j1jj20zk0m8e81.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giph4baakhj20zk0m8h5q.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipetv6p75j20zk0m8x6p.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipetlbztpj20zk0m84qp.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipewr8iypj20zk0m8b29.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="../index.html">Home</a></span><i class="ic i-angle-right"></i>
<span  itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="../categories/%E6%98%87%E8%85%BE/" itemprop="item" rel="index" title="In 昇腾"><span itemprop="name">昇腾</span></a>
<meta itemprop="position" content="1" /></span>
<i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="../categories/%E6%98%87%E8%85%BE/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="item" rel="index" title="In 深度学习"><span itemprop="name">深度学习</span></a>
<meta itemprop="position" content="2" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="en">
  <link itemprop="mainEntityOfPage" href="https://colsons.github.io/archives/bc57630c.html">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="../images/avatar.jpg">
    <meta itemprop="name" content="绯色鱼">
    <meta itemprop="description" content=", ">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="绯色鱼的博客">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <p>涵盖了 keras，tensorflow，torch，ms 多框架的 LSTM 模型。</p>
<p><span id="more"></span></p>
<p>原始开发环境：华为云昇腾 Ascend 下 mindspore1.8 下</p>
<p>可使用资源：CPU，NPU-Ai core，NPU-HBM</p>
<p>个人使用流程：【NPU-HBM 和 NPU-Ai core 的关系类似 CPU 和 GPU】</p>
<p>①keras 模型训练</p>
<p>②切换 tensorflow 模型训练</p>
<p>③切换 torch 模型训练</p>
<p>④切换 torch+NPU-Ai core 模型训练</p>
<p>⑤切换 mindspore+NPU-HBM+NPU-Ai core 模型训练</p>
<p>总结，一个算法任务，算是把所有框架换了个遍，就差 torch+GPU 了，以后说不定会补充一下</p>
<p>★重点在于④⑤，前面三个比较常规</p>
<h3 id="1-keras模型训练"><a class="anchor" href="#1-keras模型训练">#</a> 1 keras 模型训练</h3>
<p>首先区分两种训练模型，不管哪个框架，都有两种写法：①开箱训练【自己起的，并非官方命名，只是为了区分】：模型的训练函数自己定义，需要手写整个训练流程的逻辑；②闭箱训练：直接调用 model.train，只需要自己设置超参即可，不用管训练逻辑。这里 5 种训练方式也是由闭箱训练慢慢切换成了开箱训练。</p>
<p>本次教程使用 LSTM 做时序预测，一开始是简单 lstm 后面改成双向，增加注意力机制，算是我自己整个项目流程，由简单到复杂。</p>
<h4 id="11-数据集"><a class="anchor" href="#11-数据集">#</a> 1.1 数据集</h4>
<p>数据源为两个 npy 文件：X：4000×400×32；Y：4000×400×1</p>
<p>数据 X 介绍：4000 个样本，每个样本为 400×32</p>
<p>数据 Y 介绍：其实是 4000×1，中间 400 是扩展的，例如样本 x1 对应要预测的数值 y1，这里扩展成 [y1，y1，....，y1].shape=400×1</p>
<p>数据预处理：至少有归一化，别的处理看你自己的数据特点自行处理。</p>
<p>划分数据集 3:1:1 = 训练集：验证集：测试集 = 2400:800:800</p>
<pre class=" language-language-python"><code class="language-language-python">from keras.layers import Input, Dense, LSTM
from keras.models import Model
from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
import sys, os, time
import matplotlib.pyplot as plt
import numpy as np

plt.rcParams['font.sans-serif'] = ['SimHei'] # 用来正常显示中文标签SimHei
plt.rcParams['axes.unicode_minus'] = False # 用来正常显示负号

# numpy矩阵类型即可
train_X, train_Y = ...
valid_X, valid_Y = ...
test_X, test_Y = ...

# 模型构建
input1 = Input(shape=(train_x.shape[1], train_x.shape[2]))   # 输入大小
lstm = input1
lstm = LSTM(units=128,dropout=0.2,return_sequences=True)(lstm) 
lstm = LSTM(units=64,dropout=0.2,return_sequences=True)(lstm)
output = Dense(1)(lstm)   # 输出维度
model = Model(input1, output)   
model.compile(loss='mse', optimizer='adam')     # metrics=["mae"]
model.summary()

# 配置模型保存信息
check_point = ModelCheckpoint(filepath='model.h5', monitor='val_loss',save_best_only=True, mode='auto')

# 早停法     
early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='auto')

# 如果tensorboard做可视化 就去掉注释
# tensorboard_callback = TensorBoard(log_dir="board")

# 模型训练
history = model.fit(train_X, train_Y, batch_size=64, epochs=20, verbose=2,validation_data=(valid_X, valid_Y), callbacks=[check_point, early_stop])

# 损失函数曲线可视化
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show()

# 数据预测
y_pred = model.predict(test_X)
</code></pre>
<h3 id="2-tensorflow模型训练"><a class="anchor" href="#2-tensorflow模型训练">#</a> 2 tensorflow 模型训练</h3>
<p>与 keras 几乎相同，只不过不需要 keras 包了，要知道 keras 的前置是 tensorflow。如果你的环境欧 keras 不兼容，可以尝试直接用 tensorflow，而且 keras 与昇腾平台关联不大，tensorflow 和昇腾有一定联系。</p>
<p>替换模型构建部分即可</p>
<pre class=" language-language-python"><code class="language-language-python">from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Bidirectional,Dropout
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
import tensorflow as tf
import tensorflow.python.keras as keras
from tensorflow.python.keras import backend as K

# 另一种写法
model = Sequential()
model.add(Bidirectional(LSTM(64,return_sequences=True),input_shape =(400,32),merge_mode='concat'))
model.add(Dense(1))
model.compile(loss='mse', optimizer='adam')     # metrics=["mae"]
model.summary()

# 原来的写法，按照keras的写法也行
# input1 = Input(shape=(train_x.shape[1], train_x.shape[2]))   # 输入大小
# lstm = input1
# lstm = LSTM(units=64,dropout=0.4,return_sequences=True)(lstm)
# lstm = LSTM(units=16,dropout=0.4,return_sequences=True)(lstm)
# output = Dense(1)(lstm)
# model = Model(input1, output) 
</code></pre>
<h3 id="3-torch模型训练"><a class="anchor" href="#3-torch模型训练">#</a> 3 torch 模型训练</h3>
<p>三集划分</p>
<pre class=" language-language-python"><code class="language-language-python">(2400, 400, 32) (2400, 400, 1)
(800, 400, 32) (800, 400, 1)
(800, 400, 32) (800, 400, 1)

# torch中lstm有隐藏层，并且添加了注意力机制，如果隐藏层大小调整32，这里也要做调整16->32
(2400, 400, 32) (2400, 16, 1)
(800, 400, 32) (800, 16, 1)
(800, 400, 32) (800, 16, 1)
</code></pre>
<p>预处理部分</p>
<pre class=" language-language-python"><code class="language-language-python"># 这里还是numpy格式
train_x, train_y = ...
val_x, val_y = ...
test_x, test_y = ...

train_x, train_y = [torch.Tensor(xx) for xx in train_x], [torch.Tensor(yy) for yy in train_y]
val_x, val_y = [torch.Tensor(xx) for xx in val_x], [torch.Tensor(yy) for yy in val_y]
test_x, test_y = [torch.Tensor(xx) for xx in test_x], [torch.Tensor(yy) for yy in test_y]

train_dataset = torch.utils.data.TensorDataset(torch.stack(train_x), torch.stack(train_y))
val_dataset = torch.utils.data.TensorDataset(torch.stack(val_x), torch.stack(val_y))
test_dataset = torch.utils.data.TensorDataset(torch.stack(test_x), torch.stack(test_y))

batch_size = 16

# 数据加载器构建，训练集和验证集打乱，测试集为了分析每次训练结果，最好不打乱
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)
</code></pre>
<p>模型构建【相比于之前增加了注意力机制 + 单向 LSTM 变双向 LSMT】</p>
<pre class=" language-language-python"><code class="language-language-python">class AttentionLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, batch_size):
        super(AttentionLSTM, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.batch_size = batch_size
        self.isattention = False
        # bidirectional：是否为双向模式
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True,bidirectional=True,dropout=0.4)
        # 如果单向， 下面两条不需要有*2
        self.attention = nn.Linear(hidden_size*2, hidden_size)
        self.out = nn.Linear(hidden_size*2, output_size)
        
    def forward(self, input):
        h_0 = torch.randn(2, self.batch_size, self.hidden_size)
        c_0 = torch.randn(2, self.batch_size, self.hidden_size)
        # LSTM编码
        output, (hidden, cell) = self.lstm(input)
        # 计算注意力权重
        attn_weights = torch.softmax(self.attention(output), dim=1)
        # 计算注意力向量
        attn_vectors = torch.bmm(attn_weights.transpose(1, 2), output)

        # 将注意力向量和LSTM输出相加并通过线性层得到最终输出
        output = torch.relu(attn_vectors.squeeze(1))
        output = self.out(output)
        return output
</code></pre>
<p>超参训练</p>
<pre class=" language-language-python"><code class="language-language-python">input_size = 32
hidden_size = 16
output_size = 1

lr = 0.001
epochs = 10
early_patience = 3

# 创建模型
model = AttentionLSTM(input_size=input_size, hidden_size=hidden_size, output_size=output_size, batch_size=batch_size)

# 定义损失函数和优化器
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)

# 训练模型
train_loss_list_epoch = []
valid_loss_list_epoch = []
train_loss_list_steps = []
valid_loss_list_steps = []
valid_loss_min = 1
bad_epoch = 0
t1 = time.time()
for epoch in range(epochs):
    t2 = time.time()
    model.train()
    train_loss_list_step = []
    for i, (inputs, labels) in enumerate(train_loader):
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        train_loss_list_step.append(loss.item())
        optimizer.step()
    
    model.eval()
    valid_loss_list_step = []
    for _valid_X, _valid_Y in val_loader:
        pred_Y = model(_valid_X)
        loss = criterion(pred_Y, _valid_Y)
        valid_loss_list_step.append(loss.item())
    train_loss_cur = np.mean(train_loss_list_step)
    valid_loss_cur = np.mean(valid_loss_list_step)
    train_loss_list_epoch.append(train_loss_cur)
    valid_loss_list_epoch.append(valid_loss_cur)
    train_loss_list_steps += train_loss_list_step
    valid_loss_list_steps += valid_loss_list_step
    t3 = time.time()
    print('Epoch [&#123;&#125;/&#123;&#125;], Train-loss: &#123;:.4f&#125;, Val-loss: &#123;:.4f&#125;, Epoch-Time &#123;:.1f&#125;s, All Make Time &#123;:.1f&#125;s'.format(epoch+1, epochs, train_loss_cur, valid_loss_cur, t3-t2, t3-t1))
    # 早停机制
    if valid_loss_cur < valid_loss_min:
        valid_loss_min = valid_loss_cur
        bad_epoch = 0
    else:
        bad_epoch += 1
        if bad_epoch >= early_patience:
            print(" The training stops early in epoch &#123;&#125;".format(epoch))
            break
</code></pre>
<p>可视化损失函数</p>
<pre class=" language-language-python"><code class="language-language-python">plt.plot(train_loss_list_epoch, c='blue')
plt.plot(valid_loss_list_epoch, c='green')
plt.show()
</code></pre>
<p>模型预测</p>
<pre class=" language-language-python"><code class="language-language-python"># 在测试集上进行评估
y_ture = []
y_pred = []
with torch.no_grad():
    for inputs, labels in test_loader:
        outputs = model(inputs)
        y_pred += [np.mean(qa) for qa in outputs.tolist()]
        y_ture += [np.mean(qb) for qb in labels.tolist()]
</code></pre>
<h3 id="4-torchnpu-ai-core模型训练"><a class="anchor" href="#4-torchnpu-ai-core模型训练">#</a> 4 torch+NPU-Ai core 模型训练</h3>
<p>从这开始真正调用昇腾平台 NPU-Ai core 资源，加速训练</p>
<p>在 3 的基础上面修改</p>
<pre class=" language-language-python"><code class="language-language-python"># 1. 创建模型，最后加了.npu()
model = AttentionLSTM(input_size=input_size, hidden_size=hidden_size, output_size=output_size, batch_size=batch_size).npu()

# 2. 每次加载这个数据加载器的时候 数据放到NPU
for i, (inputs, labels) in enumerate(train_loader):
	inputs,labels = inputs.npu(),labels.npu()
</code></pre>
<h3 id="5-mindsporenpu-hbmnpu-ai-core模型训练"><a class="anchor" href="#5-mindsporenpu-hbmnpu-ai-core模型训练">#</a> 5 mindspore+NPU-HBM+NPU-Ai core 模型训练</h3>
<pre class=" language-language-python"><code class="language-language-python">import sys, os, time
import pandas as pd
import numpy as np
import random

from sklearn import preprocessing
from sklearn.metrics import mean_squared_error as mse
from sklearn.model_selection import train_test_split
from scipy import signal
import pickle
import mindspore
import mindspore as ms
from mindvision.engine.callback import LossMonitor
import mindspore.nn as nn
from mindspore.ops.function import broadcast_to
from mindspore.ops import grad
import mindspore.dataset as ds
from mindspore.context import ParallelMode
from mindspore.nn.wrap.cell_wrapper import WithLossCell
from mindspore import context, ParameterTuple
from mindspore.train import Model, CheckpointConfig, ModelCheckpoint, LossMonitor
from mindspore.communication import init
from mindspore.train.callback import EarlyStopping
</code></pre>
<h4 id="51-配置mindspore使用的处理器"><a class="anchor" href="#51-配置mindspore使用的处理器">#</a> 5.1 配置 mindspore 使用的处理器</h4>
<pre class=" language-language-python"><code class="language-language-python"># .py 增加全局代码，使用Ascend，device_id=0如果不行，查看自己的处理器逻辑序号，注意不是物理序号
# 在老版本Aicore处理器应该选择‘DaVinci’，但是现在淘汰了这个参数，Ascend自动选择HBM和Aicore
mindspore.set_context(mode=ms.GRAPH_MODE, device_target="Ascend", device_id=0)
init()

# 序号获取/查看, 终端里面
ls /dev/davinci*
# 看打印的*对应的号即是物理序号

# 将得到的对应序号换掉下面*, 终端里面
npu-smi info -t phyid-remap -p *
# 即可查看详情
</code></pre>
<table>
<thead>
<tr>
<th style="text-align:center">字段</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Chip Physical ID</td>
<td style="text-align:center">芯片物理 ID</td>
</tr>
<tr>
<td style="text-align:center">Chip Logic ID</td>
<td style="text-align:center">芯片逻辑 ID</td>
</tr>
<tr>
<td style="text-align:center">NPU ID</td>
<td style="text-align:center">设备 ID</td>
</tr>
<tr>
<td style="text-align:center">Chip ID</td>
<td style="text-align:center">芯片 ID</td>
</tr>
</tbody>
</table>
<h4 id="52-网络构建调整"><a class="anchor" href="#52-网络构建调整">#</a> 5.2 网络构建调整</h4>
<pre class=" language-language-python"><code class="language-language-python">class AttentionLSTM(nn.Cell):
    def __init__(self, input_size, hidden_size, output_size, batch_size):
        super(AttentionLSTM, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.batch_size = batch_size
        
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True,bidirectional=True)
        
        self.attention = nn.Dense(hidden_size*2, hidden_size)
        self.out = nn.Dense(hidden_size*2, output_size)
        
        
    def construct(self, input):
        # LSTM编码 
        output, (hidden, cell) = self.lstm(input)
        # 计算注意力权重
        softmax = mindspore.ops.Softmax(axis=1)
        attn_weights = softmax(self.attention(output))
        # 计算注意力向量
        transpose = mindspore.ops.Transpose()
        batmatmul = mindspore.ops.BatchMatMul()
        attn_vectors =batmatmul(transpose(attn_weights, (0, 2, 1)), output)
        # 将注意力向量和LSTM输出相加并通过线性层得到最终输出
        relu = nn.ReLU()
        output = relu(attn_vectors)
        output = self.out(output)
        return output
</code></pre>
<h4 id="53-数据加载器调整"><a class="anchor" href="#53-数据加载器调整">#</a> 5.3 数据加载器调整</h4>
<pre class=" language-language-python"><code class="language-language-python"># 模型输入的数据格式有一定要求，按照mindspore样例做了测试
# 总结出以下结论
# train_x, train_y
# val_x, val_y
# test_x, test_y  这三个都是任意格式
# 设置构建器
class MyIterable:
    def __init__(self, data, label):
        self._index = 0
        self._data = data
        self._label = label

    def __next__(self):
        if self._index >= len(self._data):
            raise StopIteration
        else:
            item = (self._data[self._index], self._label[self._index])
            self._index += 1
            return item

    def __iter__(self):
        self._index = 0
        return self

    def __len__(self):
        return len(self._data)

train_generator = ds.GeneratorDataset(source=MyIterable(train_x.asnumpy(),train_y.asnumpy()), column_names=["data", "label"], shuffle=True)
val_generator = ds.GeneratorDataset(source=MyIterable(val_x.asnumpy(),val_y.asnumpy()), column_names=["data", "label"], shuffle=True)
test_generator = ds.GeneratorDataset(source=MyIterable(test_x.asnumpy(),test_y.asnumpy()), column_names=["data", "label"])

train_loader = train_generator.batch(batch_size=batch_size)
val_loader = val_generator.batch(batch_size=batch_size)
test_loader = test_generator.batch(batch_size=batch_size)

train_loader = train_loader.repeat(1)
val_loader = val_loader.repeat(1)
test_loader = test_loader.repeat(1)
# 最后一行虽然重复了一次，看上去什么也没干，实际上调整了数据类型，此种类型可以投入网络直接训练，batch处理后的不行
</code></pre>
<h4 id="54-网络训练"><a class="anchor" href="#54-网络训练">#</a> 5.4 网络训练</h4>
<pre class=" language-language-python"><code class="language-language-python">input_size = ...
hidden_size = ...
output_size = ...
batch_size = ...
lr = ...

network = AttentionLSTM(input_size=input_size, hidden_size=hidden_size, output_size=output_size, batch_size=batch_size)
# 定义优化器
optimizer = nn.Adam(params=network.trainable_params(),learning_rate=lr)
net_loss = nn.MSELoss()
# 初始化模型参数，metrics指标是验证集需要的
model = ms.Model(network, loss_fn=net_loss, optimizer=optimizer, metrics=&#123;'loss','mae','mse'&#125;)

history = model.fit(
    epoch=50,
    train_dataset = train_loader, 
    valid_dataset = val_loader,
    callbacks=[ms.LossMonitor(train_x.shape[0]//batch_size)]
)
</code></pre>
<h4 id="55-模型预测"><a class="anchor" href="#55-模型预测">#</a> 5.5 模型预测</h4>
<pre class=" language-language-python"><code class="language-language-python">y_pred = model.predict(test_x)
y_pred = y_pred.mean(axis=1)
y_true = test_y.mean(axis=1)
</code></pre>
<h4 id="6-总结"><a class="anchor" href="#6-总结">#</a> 6. 总结</h4>
<p>早停法建议一开始训练不要使用，先尝试几百个批次之类固定训练，多次训练感觉容易过拟合再考虑，如上实验中，有时下降的慢或者早停的耐心参数过低会导致对于整个训练过程的不明确，不知道过拟合还是欠拟合，所以，慎用啊。</p>
<p>batch-size 的设置有时和网络模型大小也是有关系的，如设置 16，模型每 steps16×400×32，如果网络构建没有固定输出，输入之类，batch-size 的大小也是有一定设计理念的。</p>

      <div class="tags">
          <a href="../tags/python/" rel="tag"><i class="ic i-tag"></i> python</a>
          <a href="../tags/lstm/" rel="tag"><i class="ic i-tag"></i> lstm</a>
          <a href="../tags/mindspore/" rel="tag"><i class="ic i-tag"></i> mindspore</a>
          <a href="../tags/keras/" rel="tag"><i class="ic i-tag"></i> keras</a>
          <a href="../tags/torch/" rel="tag"><i class="ic i-tag"></i> torch</a>
          <a href="../tags/tensorflow/" rel="tag"><i class="ic i-tag"></i> tensorflow</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">Edited on</span>
    <time title="Modified: 2023-08-09 15:51:52" itemprop="dateModified" datetime="2023-08-09T15:51:52+08:00">2023-08-09</time>
  </span>
  <span id="archives/bc57630c.html" class="item leancloud_visitors" data-flag-title="LSTM 昇腾平台全框架指南" title="Views">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">Views</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">times</span>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> Donate</button>
  <p>Give me a cup of [coffee]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="../images/wechatpay.png" alt="绯色鱼 WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div>
        <img data-src="../images/alipay.png" alt="绯色鱼 Alipay">
        <p>Alipay</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>Post author:  </strong>绯色鱼 <i class="ic i-at"><em>@</em></i>绯色鱼的博客
  </li>
  <li class="link">
    <strong>Post link: </strong>
    <a href="../https:/colsons.github.io/archives/bc57630c.html" title="LSTM 昇腾平台全框架指南">https://colsons.github.io/archives/bc57630c.html</a>
  </li>
  <li class="license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="28195b23.html" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva3.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giclj9410cj20zk0m8h12.jpg" title="Selenium爬虫使用中阶攻略">
  <span class="type">Previous Post</span>
  <span class="category"><i class="ic i-flag"></i> 爬虫</span>
  <h3>Selenium爬虫使用中阶攻略</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="75f60fdc.html" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva3.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gicli9lfebj20zk0m84qp.jpg" title="VUE2的Hello World">
  <span class="type">Next Post</span>
  <span class="category"><i class="ic i-flag"></i> 前端</span>
  <h3>VUE2的Hello World</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="Contents">
          <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-keras%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.</span> <span class="toc-text"> 1 keras 模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.</span> <span class="toc-text"> 1.1 数据集</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-tensorflow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">2.</span> <span class="toc-text"> 2 tensorflow 模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-torch%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">3.</span> <span class="toc-text"> 3 torch 模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-torchnpu-ai-core%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">4.</span> <span class="toc-text"> 4 torch+NPU-Ai core 模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-mindsporenpu-hbmnpu-ai-core%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">5.</span> <span class="toc-text"> 5 mindspore+NPU-HBM+NPU-Ai core 模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#51-%E9%85%8D%E7%BD%AEmindspore%E4%BD%BF%E7%94%A8%E7%9A%84%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-number">5.1.</span> <span class="toc-text"> 5.1 配置 mindspore 使用的处理器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#52-%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA%E8%B0%83%E6%95%B4"><span class="toc-number">5.2.</span> <span class="toc-text"> 5.2 网络构建调整</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#53-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8%E8%B0%83%E6%95%B4"><span class="toc-number">5.3.</span> <span class="toc-text"> 5.3 数据加载器调整</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#54-%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83"><span class="toc-number">5.4.</span> <span class="toc-text"> 5.4 网络训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#55-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="toc-number">5.5.</span> <span class="toc-text"> 5.5 模型预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-%E6%80%BB%E7%BB%93"><span class="toc-number">5.6.</span> <span class="toc-text"> 6. 总结</span></a></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="Related">
        <ul>
          <li class="active"><a href="" rel="bookmark" title="LSTM 昇腾平台全框架指南">LSTM 昇腾平台全框架指南</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="Overview">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="绯色鱼"
      data-src="../images/avatar.jpg">
  <p class="name" itemprop="name">绯色鱼</p>
  <div class="description" itemprop="description"></div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="../archives/">
        <span class="count">37</span>
        <span class="name">posts</span>
      </a>
    </div>
    <div class="item categories">
      <a href="../categories/">
        <span class="count">17</span>
        <span class="name">categories</span>
      </a>
    </div>
    <div class="item tags">
      <a href="../tags/">
        <span class="count">29</span>
        <span class="name">tags</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NvbHNvbnM=" title="https:&#x2F;&#x2F;github.com&#x2F;colsons"><i class="ic i-github"></i></span>
      <span class="exturl item email" data-url="bWFpbHRvOjMzNTYwMTYzNjlAcXEuY29t" title="mailto:3356016369@qq.com"><i class="ic i-envelope"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="../index.html" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>汇总</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="../categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

        
  <li class="item">
    <a href="../tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>

        
  <li class="item">
    <a href="../archives/" rel="section"><i class="ic i-list-alt"></i>归档</a>
  </li>

  </ul>
    
  <li class="item">
    <a href="../friends/" rel="section"><i class="ic i-heart"></i>码友</a>
  </li>

    
  <li class="item">
    <a href="../links/" rel="section"><i class="ic i-magic"></i>链接</a>
  </li>

    
  <li class="item">
    <a href="../about/" rel="section"><i class="ic i-user"></i>关于</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="28195b23.html" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="75f60fdc.html" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>Random Posts</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/" title="In 离散数学">离散数学</a>
</div>

    <span><a href="dcb78086.html" title="Matlab-矩阵基本知识-01">Matlab-矩阵基本知识-01</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="In 机器学习">机器学习</a>
</div>

    <span><a href="efc46ea5.html" title="一篇文章了解PCA,MDS的推导过程">一篇文章了解PCA,MDS的推导过程</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E9%9A%8F%E7%AC%94/" title="In 随笔">随笔</a>
</div>

    <span><a href="ae9d7f26.html" title="DOS命令中文乱码一行命令解决">DOS命令中文乱码一行命令解决</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/Git/" title="In Git">Git</a>
</div>

    <span><a href="92f60f59.html" title="Git远程无法clone仓库或者链接不到">Git远程无法clone仓库或者链接不到</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="In 机器学习">机器学习</a>
</div>

    <span><a href="d5527f55.html" title="聚类阶段整理（2）-聚类介绍">聚类阶段整理（2）-聚类介绍</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E8%80%83%E7%A0%94/" title="In 考研">考研</a>
</div>

    <span><a href="1cad76d6.html" title="考研之数据结构编程笔记">考研之数据结构编程笔记</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="In 深度学习">深度学习</a>
</div>

    <span><a href="68fa613c.html" title="「转载」Bert中文情感分类分析-tf1.14">「转载」Bert中文情感分类分析-tf1.14</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E5%89%8D%E7%AB%AF/" title="In 前端">前端</a>
</div>

    <span><a href="d71e34f5.html" title="Django的路由关系与静态资源路径设置">Django的路由关系与静态资源路径设置</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="In 机器学习">机器学习</a>
</div>

    <span><a href="1699753b.html" title="机器学习-模型评估与选择(下)-02">机器学习-模型评估与选择(下)-02</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="In 机器学习">机器学习</a>
</div>

    <span><a href="6c46850c.html" title="多维标度数据降维之MDS(python× Matlab√)">多维标度数据降维之MDS(python× Matlab√)</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>Recent Comments</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2010 – 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">绯色鱼 @ Lab Chen</span>
  </div>
  <div class="powered-by">
    Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: 'archives/bc57630c.html',
    favicon: {
      show: "（●´3｀●）Goooood",
      hide: "(´Д｀)Booooom"
    },
    search : {
      placeholder: "Search for Posts",
      empty: "We didn't find any results for the search: ${query}",
      stats: "${hits} results found in ${time} ms"
    },
    valine: true,fancybox: true,
    copyright: 'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="../js/app.js?v=0.2.5"></script>




</body>
</html>
